{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,LSTM, Conv1D, Activation, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import keras\n",
    "\n",
    "\n",
    "from sz_utils import data_handler\n",
    "import pandas as pd\n",
    "\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gpu is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# collect the data\n",
    "preictal, interictal = data_handler.make_patient_windows(\"chb01\")\n",
    "\n",
    "# make the labels\n",
    "X = np.concatenate((preictal, interictal), axis=0)\n",
    "y = np.concatenate((np.ones((preictal.shape[0], 1)), np.zeros((interictal.shape[0], 1))), axis=0)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.random.permutation(np.arange(X.shape[0]))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Split test data into validation and test\n",
    "val_size = int(X_test.shape[0] * 0.5)\n",
    "X_val = X_test[:val_size]\n",
    "y_val = y_test[:val_size]\n",
    "X_test = X_test[val_size:]\n",
    "y_test = y_test[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (672, 1280, 22) y_train shape: (672, 1) X_val shape: (84, 1280, 22) y_val shape: (84, 1) X_test shape: (84, 1280, 22) y_test shape: (84, 1)\n"
     ]
    }
   ],
   "source": [
    "# shapes\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape, \"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape, \"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 \n",
    "input_shape_dataset = (X_train.shape[1], X_train.shape[2])\n",
    "input_shape_dataset\n",
    "\n",
    "def create_model_cnn_basic_1_layer(\n",
    "    input_shape_dataset: tuple = input_shape_dataset,\n",
    "    num_classes: int = num_classes,\n",
    "    debug: bool = False,\n",
    "    filters: int = 256,\n",
    "    kernel_size: int = 3,\n",
    "    pool_size: int = 2,\n",
    "    dropout: float = 0.1,\n",
    "    dense_size: int = 64,\n",
    "    loss: str = \"binary_crossentropy\",\n",
    "    optimizer: str = \"adam\",\n",
    "    metrics: list = [\"accuracy\"],\n",
    "\n",
    ") -> tf.keras.Model:\n",
    "\n",
    "    \"\"\"This function creates a basic convolutional neural network model with 2 convolutional layers, 2 dense layers and a softmax layer\n",
    "\n",
    "    :param input_shape_dataset: shape of the input data\n",
    "    :type input_shape_dataset: tuple\n",
    "    :param num_classes: number of classes\n",
    "    :type num_classes: int\n",
    "    :return: return a model\n",
    "    :rtype: tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        print(\"------------model summary---------------\")\n",
    "        print(\"input_shape_dataset\", input_shape_dataset)\n",
    "        print(\"num_classes\", num_classes)\n",
    "\n",
    "    input_shape_dataset: tuple\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters, kernel_size, input_shape=(input_shape_dataset)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_size))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 1280, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ns = (X, y)\n",
    "dataset_ns[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class Experiment:\n",
    "    experiment_name: str\n",
    "    model_name: str\n",
    "    model: tf.keras.Model\n",
    "    dataset: tuple\n",
    "    hyperparameters: dict\n",
    "    metrics: dict\n",
    "\n",
    "    def __init__(self, experiment_name, model_name, model, dataset, hyperparameters, metrics, num_folds=5):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.metrics = metrics\n",
    "        self.num_folds = num_folds\n",
    "        self.fold_no = 1\n",
    "        self.acc_per_fold = []\n",
    "        self.loss_per_fold = []\n",
    "        self.kfold = KFold(n_splits=self.num_folds, shuffle=True)\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "\n",
    "    def fit_evaluate(self):\n",
    "        try:\n",
    "            mlflow.tensorflow.autolog()\n",
    "            for i, (train, test) in enumerate(self.kfold.split(self.dataset[0], self.dataset[1])):\n",
    "                with mlflow.start_run(run_name=f\"fold_{i}\", nested=True):\n",
    "                    self.train = train\n",
    "                    self.test = test\n",
    "                    history = self.model.fit(self.dataset[0][train], self.dataset[1][train], epochs=self.hyperparameters[\"epochs\"], verbose=1)\n",
    "                    scores = self.model.evaluate(self.dataset[0][test], self.dataset[1][test], verbose=0)\n",
    "                    print(f'Score for fold {self.fold_no}: {self.model.metrics_names[0]} of {scores[0]}; {self.model.metrics_names[1]} of {scores[1]*100}%')\n",
    "                    self.acc_per_fold.append(scores[1] * 100)\n",
    "                    mlflow.log_param(\"acc_per_fold\", self.acc_per_fold)\n",
    "                    self.loss_per_fold.append(scores[0])\n",
    "                    self.log_metrics(history)\n",
    "                    self.fold_no += 1\n",
    "                # mlflow.end_run()\n",
    "\n",
    "            mlflow.log_artifact(self._log_graphs(history), artifact_path='Artifacts')\n",
    "\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(\"El error se produce en el fit, el error es: \", e)\n",
    "\n",
    "    def set_experiment(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_params(self):\n",
    "        mlflow.log_param(\"model_name\", self.model_name)\n",
    "        for key, value in self.hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "    def log_metrics(self, history):\n",
    "        for metric_name, metric_values in history.history.items():\n",
    "            for epoch, value in enumerate(metric_values):\n",
    "                mlflow.log_metric(f\"{metric_name}\", value, step=epoch)\n",
    "\n",
    "    def _log_graphs(self, history):\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "            \n",
    "            # Accuracy plot\n",
    "            ax[0].plot(history.history['accuracy'], label='train')\n",
    "            ax[0].plot(history.history['val_accuracy'], label='val')\n",
    "            ax[0].set_title('Accuracy')\n",
    "            ax[0].set_xlabel('Epoch')\n",
    "            ax[0].set_ylabel('Accuracy')\n",
    "            ax[0].legend()\n",
    "        \n",
    "            # Loss plot\n",
    "            ax[1].plot(history.history['loss'], label='train')\n",
    "            ax[1].plot(history.history['val_loss'], label='val')\n",
    "            ax[1].set_title('Loss')\n",
    "            ax[1].set_xlabel('Epoch')\n",
    "            ax[1].set_ylabel('Loss')\n",
    "            ax[1].legend()\n",
    "            \n",
    "            # Save the plots to a file\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('graphs.png')\n",
    "            return 'graphs.png'\n",
    "            \n",
    "    def log_artifacts(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        self.set_experiment()\n",
    "        self.log_params()\n",
    "        history = self.fit_evaluate()\n",
    "        artifact_path = self._log_graphs(history)\n",
    "        mlflow.log_artifact(artifact_path, artifact_path='Artifacts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze if it is necessary to use gc.collect()\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "def register_experiment(experiment_name, model_name, model, dataset, hyperparameters, metrics, num_folds=5):\n",
    "    # create an instance of Experiment class\n",
    "    experiment = Experiment(experiment_name, model_name, model, dataset, hyperparameters, metrics, num_folds=num_folds)\n",
    "\n",
    "    # execute the methods of Experiment class\n",
    "    with mlflow.start_run(nested=True):\n",
    "        experiment.set_experiment()\n",
    "        experiment.log_params()\n",
    "        experiment.fit_evaluate()\n",
    "        experiment.log_artifacts()\n",
    "        experiment.log_metrics()\n",
    "\n",
    "        return experiment   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = dataset_ns,\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 11,\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 1,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 32,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")\n",
    "\n",
    "experiment_2 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = dataset_ns,\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 17,\n",
    "        \"filters\": 128,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 16,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Experiment at 0x26384da4610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "register_experiment() missing 5 required positional arguments: 'model_name', 'model', 'dataset', 'hyperparameters', and 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\crist\\Documents\\tesis\\SeizurePrediction\\src\\notebooks\\dev_experiment_module.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/crist/Documents/tesis/SeizurePrediction/src/notebooks/dev_experiment_module.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m register_experiment(experiment_1)\n",
      "\u001b[1;31mTypeError\u001b[0m: register_experiment() missing 5 required positional arguments: 'model_name', 'model', 'dataset', 'hyperparameters', and 'metrics'"
     ]
    }
   ],
   "source": [
    "register_experiment(experiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "register_experiment() missing 5 required positional arguments: 'model_name', 'model', 'dataset', 'hyperparameters', and 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\crist\\Documents\\tesis\\SeizurePrediction\\src\\notebooks\\dev_experiment_module.ipynb Cell 10\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/crist/Documents/tesis/SeizurePrediction/src/notebooks/dev_experiment_module.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m experiments \u001b[39m=\u001b[39m [experiment_1, experiment_2]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/crist/Documents/tesis/SeizurePrediction/src/notebooks/dev_experiment_module.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m experiment \u001b[39min\u001b[39;00m experiments:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/crist/Documents/tesis/SeizurePrediction/src/notebooks/dev_experiment_module.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     register_experiment(experiment)\n",
      "\u001b[1;31mTypeError\u001b[0m: register_experiment() missing 5 required positional arguments: 'model_name', 'model', 'dataset', 'hyperparameters', and 'metrics'"
     ]
    }
   ],
   "source": [
    "experiments = [experiment_1, experiment_2]\n",
    "\n",
    "for experiment in experiments:\n",
    "    register_experiment(experiment)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
