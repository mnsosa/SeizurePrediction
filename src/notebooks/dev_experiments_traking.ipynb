{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:23:17.051228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 19:23:18.994410: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2023-03-29 19:23:18.994587: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2023-03-29 19:23:19.003806: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2023-03-29 19:23:21.693095: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "from sz_utils import data_handler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getpass\n",
    "\n",
    "# check if gpu is available\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# collect the data\n",
    "preictal, interictal = data_handler.make_patient_windows(\"chb01\")\n",
    "\n",
    "# make the labels\n",
    "X = np.concatenate((preictal, interictal), axis=0)\n",
    "y = np.concatenate((np.ones((preictal.shape[0], 1)), np.zeros((interictal.shape[0], 1))), axis=0)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.random.permutation(np.arange(X.shape[0]))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Split test data into validation and test\n",
    "val_size = int(X_test.shape[0] * 0.5)\n",
    "X_val = X_test[:val_size]\n",
    "y_val = y_test[:val_size]\n",
    "X_test = X_test[val_size:]\n",
    "y_test = y_test[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,LSTM, Conv1D, Activation, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (672, 1280, 22) y_train shape: (672, 1) X_val shape: (84, 1280, 22) y_val shape: (84, 1) X_test shape: (84, 1280, 22) y_test shape: (84, 1)\n"
     ]
    }
   ],
   "source": [
    "# shapes\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape, \"X_val shape:\", X_val.shape, \"y_val shape:\", y_val.shape, \"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 \n",
    "input_shape_dataset = (X_train.shape[1], X_train.shape[2])\n",
    "input_shape_dataset\n",
    "\n",
    "def create_model_cnn_basic_1_layer(\n",
    "    input_shape_dataset: tuple = input_shape_dataset,\n",
    "    num_classes: int = num_classes,\n",
    "    debug: bool = False,\n",
    "    filters: int = 256,\n",
    "    kernel_size: int = 3,\n",
    "    pool_size: int = 2,\n",
    "    dropout: float = 0.1,\n",
    "    dense_size: int = 64,\n",
    "    loss: str = \"binary_crossentropy\",\n",
    "    optimizer: str = \"adam\",\n",
    "    metrics: list = [\"accuracy\"],\n",
    "\n",
    ") -> tf.keras.Model:\n",
    "\n",
    "    \"\"\"This function creates a basic convolutional neural network model with 2 convolutional layers, 2 dense layers and a softmax layer\n",
    "\n",
    "    :param input_shape_dataset: shape of the input data\n",
    "    :type input_shape_dataset: tuple\n",
    "    :param num_classes: number of classes\n",
    "    :type num_classes: int\n",
    "    :return: return a model\n",
    "    :rtype: tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        print(\"------------model summary---------------\")\n",
    "        print(\"input_shape_dataset\", input_shape_dataset)\n",
    "        print(\"num_classes\", num_classes)\n",
    "\n",
    "    input_shape_dataset: tuple\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters, kernel_size, input_shape=(input_shape_dataset)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_size))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:23:42.526319: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 19:23:42.528822: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (NVIDIA GeForce GTX 1650)\n",
      "2023-03-29 19:23:44.227891: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:23:44.228043: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2023-03-29 19:23:44.228434: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Experiment:\n",
    "    experiment_name: str\n",
    "    model_name: str\n",
    "    model: tf.keras.Model\n",
    "    dataset: tuple\n",
    "    hyperparameters: dict\n",
    "    metrics: dict\n",
    "\n",
    "\n",
    "    def __init__(self, experiment_name, model_name, model, dataset, hyperparameters, metrics):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.metrics = metrics      \n",
    "\n",
    "    # TODO: add kfolds\n",
    "    def fit(self):\n",
    "        # add k-fold cross validation\n",
    "\n",
    "\n",
    "        mlflow.tensorflow.autolog()\n",
    "        history = self.model.fit(self.dataset[0], self.dataset[1],\n",
    "                                    validation_data=(self.dataset[2], self.dataset[3]),\n",
    "                                    epochs=self.hyperparameters[\"epochs\"],\n",
    "                                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n",
    "        # TODO log artifacts\n",
    "        # mlflow.log_artifacts(\"graphs\", self._log_graphs(history))\n",
    "        return history\n",
    "\n",
    "    def set_experiment(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_params(self):\n",
    "        mlflow.log_param(\"model_name\", self.model_name)\n",
    "        for key, value in self.hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "    \n",
    "    def log_metrics(self, history):\n",
    "        for metric_name, metric_values in history.history.items():\n",
    "            for epoch, value in enumerate(metric_values):\n",
    "                mlflow.log_metric(f\"{metric_name}\", value, step=epoch)\n",
    "    \n",
    "    # def _log_graphs(self, history):\n",
    "        # TODO make a function to log graphs\n",
    "    \n",
    "        # Save training and validation loss and accuracy plots as artifact\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 8), dpi=100, sharex=True)\n",
    "        # ax[0].plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "        # ax[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "        # ax[0].set_title(\"Training/Validation Loss\")\n",
    "        # ax[0].set_xlabel(\"Epoch\")\n",
    "        # ax[0].set_ylabel(\"Loss\")\n",
    "        # # ax[0].set_grid(True)\n",
    "        # ax[0].legend()\n",
    "        \n",
    "        # ax[1].plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "        # ax[1].plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "        # ax[1].set_title(\"Training/Validation Accuracy\")\n",
    "        # ax[1].set_xlabel(\"Epoch\")\n",
    "        # ax[1].set_ylabel(\"Accuracy\")\n",
    "        # # ax[1].set_grid(True)\n",
    "        # ax[1].legend()\n",
    "        \n",
    "        # fig.tight_layout()\n",
    "        # fig.savefig(\"graphs.png\")\n",
    "        # plt.close(fig)\n",
    "        # return \"graphs.png\"\n",
    "        \n",
    "    def log_artifacts(self):\n",
    "        \n",
    "        pass\n",
    "\n",
    "# TODO: Analyze if it is necessary to use gc.collect()\n",
    "# import gc\n",
    "# gc.collect()\n",
    "def registrar_experiment(experiment: Experiment):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        experiment.set_experiment()\n",
    "        experiment.log_params()\n",
    "        experiment.log_metrics(experiment.fit())\n",
    "        # experiment._log_graphs(experiment.fit())\n",
    "        experiment.log_artifacts()\n",
    "\n",
    "\n",
    "experiment_1 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = (X_train, y_train, X_val, y_val),\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 11,\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 64,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")\n",
    "\n",
    "experiment_2 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = (X_train, y_train, X_val, y_val),\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 17,\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 32,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:23:46.322759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:23:51.329031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:23:51.363020: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:23:51.363106: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-03-29 19:23:54.562414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:00.767381: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:01.566329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:01.594196: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:24:01.594260: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-03-29 19:24:05.600419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "experiments = [experiment_1, experiment_2]\n",
    "\n",
    "for experiment in experiments:\n",
    "    registrar_experiment(experiment)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Experiment:\n",
    "    experiment_name: str\n",
    "    model_name: str\n",
    "    model: tf.keras.Model\n",
    "    dataset: tuple\n",
    "    hyperparameters: dict\n",
    "    metrics: dict\n",
    "\n",
    "\n",
    "    def __init__(self, experiment_name, model_name, model, dataset, hyperparameters, metrics):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.metrics = metrics      \n",
    "\n",
    "    # TODO: add kfolds\n",
    "    def fit(self):\n",
    "        # add k-fold cross validation\n",
    "\n",
    "\n",
    "        mlflow.tensorflow.autolog()\n",
    "        history = self.model.fit(self.dataset[0], self.dataset[1],\n",
    "                                    validation_data=(self.dataset[2], self.dataset[3]),\n",
    "                                    epochs=self.hyperparameters[\"epochs\"],\n",
    "                                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n",
    "        # TODO log artifacts\n",
    "        mlflow.log_artifact(self._log_graphs(history), artifact_path='Artifacts')\n",
    "        return history\n",
    "\n",
    "    def set_experiment(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_params(self):\n",
    "        mlflow.log_param(\"model_name\", self.model_name)\n",
    "        for key, value in self.hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "    \n",
    "    def log_metrics(self, history):\n",
    "        for metric_name, metric_values in history.history.items():\n",
    "            for epoch, value in enumerate(metric_values):\n",
    "                mlflow.log_metric(f\"{metric_name}\", value, step=epoch)\n",
    "        \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def _log_graphs(self, history):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax[0].plot(history.history['accuracy'], label='train')\n",
    "        ax[0].plot(history.history['val_accuracy'], label='val')\n",
    "        ax[0].set_title('Accuracy')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Accuracy')\n",
    "        ax[0].legend()\n",
    "    \n",
    "        # Loss plot\n",
    "        ax[1].plot(history.history['loss'], label='train')\n",
    "        ax[1].plot(history.history['val_loss'], label='val')\n",
    "        ax[1].set_title('Loss')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Loss')\n",
    "        ax[1].legend()\n",
    "        \n",
    "        # Save the plots to a file\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('graphs.png')\n",
    "        return 'graphs.png'\n",
    "        \n",
    "    def log_artifacts(self):\n",
    "        \n",
    "        pass\n",
    "\n",
    "# TODO: Analyze if it is necessary to use gc.collect()\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "def registrar_experiment(experiment: Experiment):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        experiment.set_experiment()\n",
    "        experiment.log_params()\n",
    "        history = experiment.fit()\n",
    "        experiment.log_metrics(history)\n",
    "        graph_path = experiment._log_graphs(history)\n",
    "        mlflow.log_artifact(graph_path, artifact_path='Artifacts')\n",
    "        experiment.log_artifacts()\n",
    "\n",
    "experiment_1 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = (X_train, y_train, X_val, y_val),\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 11,\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 1,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 32,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")\n",
    "\n",
    "experiment_2 = Experiment(\n",
    "    experiment_name = \"CNN_autolog\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset = (X_train, y_train, X_val, y_val),\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 17,\n",
    "        \"filters\": 128,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 16,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \n",
    "    },metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:24:12.701402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:13.658487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:13.685964: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:24:13.686046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-03-29 19:24:19.766869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:26.190886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:27.096796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:24:27.139554: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:24:27.139679: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-03-29 19:24:32.773701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "experiments = [experiment_1, experiment_2]\n",
    "\n",
    "for experiment in experiments:\n",
    "    registrar_experiment(experiment)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,LSTM, Conv1D, Activation, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sz_utils import data_handler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# check if gpu is available\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# collect the data\n",
    "preictal, interictal = data_handler.make_patient_windows(\"chb01\")\n",
    "\n",
    "# make the labels\n",
    "X = np.concatenate((preictal, interictal), axis=0)\n",
    "y = np.concatenate((np.ones((preictal.shape[0], 1)), np.zeros((interictal.shape[0], 1))), axis=0)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.random.permutation(np.arange(X.shape[0]))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split the data into train and test\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Split test data into validation and test\n",
    "val_size = int(X_test.shape[0] * 0.5)\n",
    "X_val = X_test[:val_size]\n",
    "y_val = y_test[:val_size]\n",
    "X_test = X_test[val_size:]\n",
    "y_test = y_test[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 \n",
    "input_shape_dataset = (X_train.shape[1], X_train.shape[2])\n",
    "input_shape_dataset\n",
    "\n",
    "def create_model_cnn_basic_1_layer(\n",
    "    input_shape_dataset: tuple = input_shape_dataset,\n",
    "    num_classes: int = num_classes,\n",
    "    debug: bool = False,\n",
    "    filters: int = 256,\n",
    "    kernel_size: int = 3,\n",
    "    pool_size: int = 2,\n",
    "    dropout: float = 0.1,\n",
    "    dense_size: int = 64,\n",
    "    loss: str = \"binary_crossentropy\",\n",
    "    optimizer: str = \"adam\",\n",
    "    metrics: list = [\"accuracy\"],\n",
    "\n",
    ") -> tf.keras.Model:\n",
    "\n",
    "    \"\"\"This function creates a basic convolutional neural network model with 2 convolutional layers, 2 dense layers and a softmax layer\n",
    "\n",
    "    :param input_shape_dataset: shape of the input data\n",
    "    :type input_shape_dataset: tuple\n",
    "    :param num_classes: number of classes\n",
    "    :type num_classes: int\n",
    "    :return: return a model\n",
    "    :rtype: tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    if debug:\n",
    "        print(\"------------model summary---------------\")\n",
    "        print(\"input_shape_dataset\", input_shape_dataset)\n",
    "        print(\"num_classes\", num_classes)\n",
    "\n",
    "    input_shape_dataset: tuple\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters, kernel_size, input_shape=(input_shape_dataset)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_size))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:25:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1475518e7886440c9716229eb7d33116', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:17.423315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:25:22.612340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 511ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:25:28 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwhws0164/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023-03-29 19:25:29.158503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:25:29.194532: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:25:29.194673: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023/03/29 19:25:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9a01b01bfebe4775ba07b26942318dcb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.11172610521316528; accuracy of 98.21428656578064%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:29.794975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:32.560999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023/03/29 19:25:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp17rkwd45/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023-03-29 19:25:37.394789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:25:37.431962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:25:37.432050: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023/03/29 19:25:37 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1a7ddc010fff412b8eadbf4e7ac0caf8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.6943904161453247; accuracy of 44.64285671710968%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:37.955999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:40.720879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023/03/29 19:25:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpi2y2f2z8/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023-03-29 19:25:46.043422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:25:46.077254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:25:46.077350: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023/03/29 19:25:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '51b8a9d5bb1f4b68aa5b50ab0c788352', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.38884949684143066; accuracy of 92.26190447807312%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:46.644247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:49.405485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023/03/29 19:25:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpukyyvrze/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023-03-29 19:25:54.276806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:25:54.310506: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:25:54.310564: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023/03/29 19:25:54 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5bcb8fff354242b6be9b1bef8cdf9d58', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.25302520394325256; accuracy of 95.23809552192688%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:54.984944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:25:57.803636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023/03/29 19:26:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpoho55mx6/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.6940484046936035; accuracy of 41.66666865348816%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:26:03.127543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-29 19:26:03.168825: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-29 19:26:03.169023: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10171 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = X\n",
    "targets = y\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "     # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    # Fit the model\n",
    "    model.fit(inputs[train], targets[train], epochs=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 1280, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ns = (X, y)\n",
    "dataset_ns[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset_ns = (X, y)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"mlflow.tensorflow\")\n",
    "\n",
    "\n",
    "class Experiment_kfolds:\n",
    "    def __init__(self, experiment_name, model_name, model, dataset_ns, hyperparameters, metrics, num_folds=5):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataset_ns = dataset_ns\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.metrics = metrics\n",
    "        self.num_folds = num_folds\n",
    "        self.fold_no = 1\n",
    "        self.acc_per_fold = []\n",
    "        self.loss_per_fold = []\n",
    "        self.kfold = KFold(n_splits=self.num_folds, shuffle=True)\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "\n",
    "    def fit(self):\n",
    "        try:\n",
    "            \n",
    "            # mlflow.tensorflow.autolog(log_models=False)\n",
    "            mlflow.tensorflow.autolog()\n",
    "            history = self.model.fit(self.dataset_ns[0][train], self.dataset_ns[1][train], epochs=self.hyperparameters[\"epochs\"], verbose=0)\n",
    "            return history\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"El erro se pruduce en el fit, el error es: \", e)\n",
    "\n",
    "    def evaluate(self, history):\n",
    "\n",
    "        try:\n",
    "                \n",
    "            scores = model.evaluate(self.dataset_ns[0][test], self.dataset_ns[1][test], verbose=0)\n",
    "            print(f'Score for fold {self.fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "            self.acc_per_fold.append(scores[1] * 100)\n",
    "            self.loss_per_fold.append(scores[0])\n",
    "            self.log_metrics(history)\n",
    "        except Exception as e:\n",
    "            print(\"El erro se pruduce en el evaluate, el error es: \", e)\n",
    "\n",
    "    def set_experiment(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_params(self):\n",
    "        mlflow.log_param(\"model_name\", self.model_name)\n",
    "        for key, value in self.hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "\n",
    "    def log_metrics(self, history):\n",
    "        for metric_name, metric_values in history.history.items():\n",
    "            for epoch, value in enumerate(metric_values):\n",
    "                mlflow.log_metric(f\"{metric_name}\", value, step=epoch)\n",
    "\n",
    "    def log_artifacts(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        self.set_experiment()\n",
    "        self.log_params()\n",
    "        for train, test in self.kfold.split(self.dataset_ns[0], self.dataset_ns[1]):\n",
    "            self.train = train\n",
    "            self.test = test\n",
    "            history = self.fit()\n",
    "            self.evaluate(history)  # pass history object returned by fit()\n",
    "            self.fold_no = self.fold_no + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "class Experiment_kfolds:\n",
    "    def __init__(self, experiment_name, model_name, model, dataset_ns, hyperparameters, metrics, num_folds=5):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataset_ns = dataset_ns\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.metrics = metrics\n",
    "        self.num_folds = num_folds\n",
    "        self.fold_no = 1\n",
    "        self.acc_per_fold = []\n",
    "        self.loss_per_fold = []\n",
    "        self.kfold = KFold(n_splits=self.num_folds, shuffle=True)\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "\n",
    "    def fit_evaluate(self):\n",
    "        try:\n",
    "            mlflow.tensorflow.autolog()\n",
    "            for i, (train, test) in enumerate(self.kfold.split(self.dataset_ns[0], self.dataset_ns[1])):\n",
    "                with mlflow.start_run(run_name=f\"fold_{i}\", nested=True):\n",
    "                    self.train = train\n",
    "                    self.test = test\n",
    "                    history = self.model.fit(self.dataset_ns[0][train], self.dataset_ns[1][train], epochs=self.hyperparameters[\"epochs\"], verbose=1)\n",
    "                    scores = model.evaluate(self.dataset_ns[0][test], self.dataset_ns[1][test], verbose=0)\n",
    "                    print(f'Score for fold {self.fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "                    self.acc_per_fold.append(scores[1] * 100)\n",
    "                    mlflow.log_param(\"acc_per_fold\", self.acc_per_fold)\n",
    "                    self.loss_per_fold.append(scores[0])\n",
    "                    self.log_metrics(history)\n",
    "                    self.fold_no = self.fold_no + 1\n",
    "                # mlflow.end_run() # This line is optional\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(\"El error se produce en el fit, el error es: \", e)\n",
    "\n",
    "\n",
    "    def set_experiment(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    def log_params(self):\n",
    "        mlflow.log_param(\"model_name\", self.model_name)\n",
    "        for key, value in self.hyperparameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "\n",
    "    def log_metrics(self, history):\n",
    "\n",
    "        for metric_name, metric_values in history.history.items():\n",
    "            for epoch, value in enumerate(metric_values):\n",
    "                mlflow.log_metric(f\"{metric_name}\", value, step=epoch)\n",
    "\n",
    "    def log_artifacts(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        self.set_experiment()\n",
    "        self.log_params()\n",
    "        self.fit_evaluate()\n",
    "\n",
    "\n",
    "def run_experiment(experiment_name, model_name, model, dataset_ns, hyperparameters, metrics, num_folds=5):\n",
    "    with mlflow.start_run():\n",
    "        experiment = Experiment_kfolds(experiment_name, model_name, model, dataset_ns, hyperparameters, metrics, num_folds)\n",
    "        experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:26:03 INFO mlflow.tracking.fluent: Experiment with name 'CNN_autolog_kfolds' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:26:04.445988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 27ms/step - loss: 823.4755 - accuracy: 0.5967\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 35.6494 - accuracy: 0.9390\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 20.0513 - accuracy: 0.9717\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6429 - accuracy: 0.9955\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2759 - accuracy: 0.9955\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6879 - accuracy: 0.9970\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2727 - accuracy: 0.9985\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0979 - accuracy: 0.9985\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5485 - accuracy: 0.9955\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 19:26:11.346315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023/03/29 19:26:16 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpf6d91mlq/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.6930347084999084; accuracy of 51.1904776096344%\n",
      "Epoch 1/12\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.4781 - accuracy: 0.9955\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.7838 - accuracy: 0.9896\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 4.6581 - accuracy: 0.9896\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2203 - accuracy: 0.9970\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6389 - accuracy: 0.9985\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:26:30 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpdf_rh9t0/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.6891950368881226; accuracy of 48.80952537059784%\n",
      "Epoch 1/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0267 - accuracy: 0.9985\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2610 - accuracy: 0.9985\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:26:43 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp1nsp3osa/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.6930980086326599; accuracy of 50.59524178504944%\n",
      "Epoch 1/12\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 0.9985\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:26:55 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpii_3v9y0/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.6932880282402039; accuracy of 48.80952537059784%\n",
      "Epoch 1/12\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4733 - accuracy: 0.9985\n",
      "Epoch 2/12\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.3945 - accuracy: 0.9985\n",
      "Epoch 3/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/12\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/12\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/29 19:27:08 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0u5t831d/model, flavor: tensorflow), fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.6930980086326599; accuracy of 50.59524178504944%\n"
     ]
    }
   ],
   "source": [
    "experiment_1_kfolds = Experiment_kfolds(\n",
    "    experiment_name = \"CNN_autolog_kfolds\",\n",
    "    # experiment_description = \"CNN con autolog y kfold\",\n",
    "    model_name = \"CNN_basic_1_layer\",\n",
    "    model = create_model_cnn_basic_1_layer(),\n",
    "    dataset_ns = dataset_ns,\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 12,\n",
    "        \"filters\": 256,\n",
    "        \"kernel_size\": 3,\n",
    "        \"pool_size\": 2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"dense_size\": 64,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "\n",
    "    },metrics = [\"accuracy\"],\n",
    "    num_folds = 5\n",
    ")\n",
    "\n",
    "run_experiment( experiment_1_kfolds.experiment_name, experiment_1_kfolds.model_name, experiment_1_kfolds.model, experiment_1_kfolds.dataset_ns, experiment_1_kfolds.hyperparameters, experiment_1_kfolds.metrics, experiment_1_kfolds.num_folds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22620"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear ram\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
